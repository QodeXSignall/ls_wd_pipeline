from importlib.resources import read_text
from urllib.parse import urlparse, parse_qs, unquote
from ls_wb_pipeline.logger import logger
from ls_wb_pipeline.settings import *
from webdav3.client import Client
from itertools import islice
from pathlib import Path
import subprocess
import requests
import tempfile
import random
import json
import time
import os
import cv2
import re




# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è WebDAV
WEBDAV_OPTIONS = {
    'webdav_hostname': os.environ.get("webdav_host"),
    'webdav_login': os.environ.get("webdav_login"),
    'webdav_password': os.environ.get("webdav_password"),
    'disable_check': True  # –û—Ç–∫–ª—é—á–∞–µ—Ç –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ
}
client = Client(WEBDAV_OPTIONS)



# –ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
if os.path.exists(DOWNLOAD_HISTORY_FILE):
    with open(DOWNLOAD_HISTORY_FILE, "r") as f:
        downloaded_videos = set(json.load(f))
else:
    downloaded_videos = set()


def save_download_history():
    with open(DOWNLOAD_HISTORY_FILE, "w") as f:
        json.dump(list(downloaded_videos), f)

def is_mounted():
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∞ –ª–∏ –ø–∞–ø–∫–∞ WebDAV –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ."""
    # 1. –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –ø—É—Ç—å –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω
    if not os.path.ismount(MOUNTED_PATH):
        return False

    # 2. –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ ‚Äî –µ—Å–ª–∏ endpoint –º—ë—Ä—Ç–≤, —Ç—É—Ç –≤—ã–ª–µ—Ç–∏—Ç OSError
    try:
        test = os.listdir(MOUNTED_PATH)
        return True
    except OSError as e:
        logger.warning(f"–ü—É—Ç—å {MOUNTED_PATH} —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω, –Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")
        return False



def mount_webdav(from_systemd=False):
    """–ú–æ–Ω—Ç–∏—Ä—É–µ—Ç WebDAV –∫–∞–∫ –ª–æ–∫–∞–ª—å–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é."""
    if is_mounted():
        logger.info("WebDAV —É–∂–µ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω.")
        return

    try:
        logger.info("–ú–æ–Ω—Ç–∏—Ä—É–µ–º WebDAV...")
        os.makedirs(MOUNTED_PATH, exist_ok=True)
        args = [
            "rclone", "mount", WEBDAV_REMOTE, MOUNTED_PATH,
            "--no-modtime"
        ]
        if not from_systemd:
            args.append("--daemon")

        subprocess.run(args, check=True)
        time.sleep(2)
        if is_mounted():
            logger.info(f"WebDAV —É—Å–ø–µ—à–Ω–æ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –≤ {MOUNTED_PATH}")
        else:
            logger.error("WebDAV –Ω–µ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω.")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ WebDAV: {e}")


def remount_webdav(from_systemd=False):
    """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–µ—Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å WebDAV, –µ—Å–ª–∏ –æ–Ω –æ—Ç–∫–ª—é—á–∏–ª—Å—è."""
    if is_mounted():
        return

    logger.warning("WebDAV –æ—Ç–∫–ª—é—á–µ–Ω. –ü–µ—Ä–µ–º–æ–Ω—Ç–∏—Ä—É–µ–º...")

    subprocess.run(["fusermount", "-uz", MOUNTED_PATH], check=False)
    time.sleep(3)

    try:
        os.makedirs(MOUNTED_PATH, exist_ok=True)
        args = ["rclone", "mount", WEBDAV_REMOTE, MOUNTED_PATH, "--no-modtime"]
        if not from_systemd:
            args.append("--daemon", )
        else:
            args += [
                "--vfs-cache-mode", "writes",
                "--dir-cache-time", "5s",
                "--poll-interval", "5s"
            ]
        subprocess.run(
            args,
            check=True
        )
        time.sleep(3)
        if is_mounted():
            logger.info("WebDAV —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω.")
        else:
            logger.error("–û—à–∏–±–∫–∞: WebDAV –Ω–µ —Å–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏ –ø–µ—Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.")
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ WebDAV: {e}")


def get_all_video_files(max_files=3):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–µ –±–æ–ª–µ–µ `max_files` –≤–∞–ª–∏–¥–Ω—ã—Ö –≤–∏–¥–µ–æ –∏–∑ WebDAV."""
    return list(islice(iter_video_files(BASE_REMOTE_DIR), max_files))


def iter_video_files(path):
    """–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä, –ª–µ–Ω–∏–≤–æ –æ–±—Ö–æ–¥–∏—Ç WebDAV –∏ yield'–∏—Ç –≤–∞–ª–∏–¥–Ω—ã–µ mp4-—Ñ–∞–π–ª—ã."""
    items = client.list(path)
    for item in items:
        item_path = sanitize_path(f"{path}/{item}")
        if client.is_dir(item_path):
            yield from iter_video_files(item_path)
        elif item.endswith(".mp4"):
            if any(reg in item for reg in BLACKLISTED_REGISTRATORS):
                logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª: {item_path} (–≤ —á—ë—Ä–Ω–æ–º —Å–ø–∏—Å–∫–µ)")
                continue
            if item_path in downloaded_videos:
                continue
            yield item_path

def sanitize_path(path):
    return path.replace("//", "/")

def count_remote_frames(webdav_client):
    """–ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ (jpg) –≤ —É–¥–∞–ª—ë–Ω–Ω–æ–π –ø–∞–ø–∫–µ."""
    try:
        items = webdav_client.list(REMOTE_FRAME_DIR)
        jpg_count = sum(1 for item in items if item.endswith(".jpg"))
        return jpg_count
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–¥—Å—á—ë—Ç–µ –∫–∞–¥—Ä–æ–≤ –≤ WebDAV: {e}")
        return 0

def clean_cloud_files_from_path(json_path, dry_run=False):
    # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
    with open(json_path, "r", encoding="utf-8") as f:
        tasks = json.load(f)
    return clean_cloud_files_from_tasks(tasks, dry_run=dry_run)

def clean_cloud_files_from_tasks(tasks, dry_run=False, save_annotated=True):
    marked_files = []
    unmarked_files = []

    for task in tasks:
        try:
            image_url = task["data"]["image"]
            parsed = urlparse(image_url)
            query = parse_qs(parsed.query)
            image_path = query.get("d", [""])[0]
            image_name = os.path.basename(image_path)
            if check_if_ann(task):
                marked_files.append(image_path)
            else:
                unmarked_files.append(image_path)
        except Exception as e:
            logger.warning(f"[EXC] –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–∞—Ä—Å–∏–Ω–≥–µ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞: {e}")
            continue
    files_to_delete = unmarked_files if save_annotated else marked_files + unmarked_files
    delete_files(files_to_delete, dry_run=dry_run)
    logger.info(f"{'[DRY RUN] ' if dry_run else ''}–£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –£–¥–∞–ª–µ–Ω–æ: {len(files_to_delete)}, "
                f"–æ—Å—Ç–∞–≤–ª–µ–Ω–æ: {len(marked_files)}")
    return {"deleted_amount": len(files_to_delete), "saved": len(marked_files), "deleted": files_to_delete}

def check_if_ann(task):
    if task.get("total_annotations", 0):
        return True


def delete_all_cloud_files(dry_run=False):
    try:
        actual_files = [f for f in os.listdir(MOUNTED_PATH) if f.lower().endswith(".jpg")]
    except Exception as e:
        logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é {MOUNTED_PATH}: {e}")
        return {"error": e}
    report =  delete_files(files=actual_files, dry_run=dry_run)
    report["saved_amount"] = 0
    report["saved"] = []
    return report


def delete_files(files, dry_run=False):
    deleted_amount = 0
    deleted = []
    for file in files:
        if dry_run:
            logger.info(f"[DRY RUN] –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–æ: {file}")
        else:
            try:
                os.remove(os.path.join("/mnt", file))
                deleted_amount += 1
                deleted.append(file)
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ {file}: {e}")
    return {"deleted": deleted, "deleted_amount": deleted_amount}


def get_all_tasks():
    page = 1
    page_size = 100
    all_tasks = []
    seen_ids = set()

    logger.info("[LS] –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π (–ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º)...")

    while True:
        url = f"{LABELSTUDIO_API_URL}/tasks?project={PROJECT_ID}&page={page}&page_size={page_size}"

        logger.debug(f"[DEBUG] URL: {url}")
        r = requests.get(url, headers=HEADERS)

        if r.status_code != 200:
            logger.error(f"[LS] –û—à–∏–±–∫–∞ {r.status_code}: {r.text}")
            return

        data = r.json()
        page_tasks = data.get("tasks", [])
        total = data.get("total")

        logger.debug(f"[DEBUG] page={page}, –ø–æ–ª—É—á–µ–Ω–æ –∑–∞–¥–∞—á: {len(page_tasks)}, total={total}")

        if not page_tasks:
            logger.info("[LS] –ü–æ–ª—É—á–µ–Ω–∞ –ø—É—Å—Ç–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞, –∑–∞–≤–µ—Ä—à–∞–µ–º.")
            break

        task_ids = [t['id'] for t in page_tasks]
        repeats = [tid for tid in task_ids if tid in seen_ids]
        if repeats:
            logger.warning(f"[LS] –ü–æ–≤—Ç–æ—Ä –∑–∞–¥–∞—á: {repeats[:5]} ... ({len(repeats)} –≤—Å–µ–≥–æ), –æ—Å—Ç–∞–Ω–æ–≤–∫–∞.")
            break

        for task in page_tasks:
            seen_ids.add(task["id"])
            all_tasks.append(task)

        if len(all_tasks) >= total:
            logger.info("[LS] –í—Å–µ –∑–∞–¥–∞—á–∏ –ø–æ–ª—É—á–µ–Ω—ã.")
            break

        page += 1

    logger.info(f"[LS] –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á: {len(all_tasks)}")
    return all_tasks


def delete_ls_tasks(tasks, dry_run=False, save_annotated=True):
    saved = 0

    logger.info("[LS] –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ —Å –ø–∞–≥–∏–Ω–∞—Ü–∏–µ–π (–ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º)...")

    to_delete = []
    for task in tasks:
        task_id = task.get("id")
        anns = task.get("total_annotations", 0)
        if not save_annotated or not anns:
            logger.debug(f"[LS DEBUG] –ó–∞–¥–∞—á–∞ {task_id} –æ—Ç–º–µ—á–µ–Ω–∞ –ø–æ–¥ —É–¥–∞–ª–µ–Ω–∏–µ - {'–Ω–µ—Ç –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π' if not anns else '–æ—Ç–∫–ª—é—á–µ–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π'}")
            to_delete.append(task_id)
            continue

    logger.info(f"[LS] –ö —É–¥–∞–ª–µ–Ω–∏—é –æ—Ç–æ–±—Ä–∞–Ω–æ: {len(to_delete)} –∑–∞–¥–∞—á")

    for task_id in to_delete:
        if dry_run:
            logger.debug(f"[DRY RUN] –ë—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ {task_id}")
        else:
            r = requests.delete(f"{LABELSTUDIO_API_URL}/tasks/{task_id}", headers=HEADERS)
            if r.status_code == 204:
                logger.debug(f"[LS DEL] –£–¥–∞–ª–µ–Ω–∞ –∑–∞–¥–∞—á–∞ {task_id}")
            else:
                logger.error(f"[ERR] –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –∑–∞–¥–∞—á—É {task_id} ‚Äî {r.status_code}: {r.text}")
    try:
        saved = len(tasks) - len(to_delete)
    except:
        pass
    logger.info(f"{'[DRY RUN] ' if dry_run else ''}–£–¥–∞–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –í—Å–µ–≥–æ —É–¥–∞–ª–µ–Ω–æ: {len(to_delete)}. –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {saved}")
    return to_delete, saved



def extract_frames(video_path, frames_per_second: float = None):
    """–†–∞–∑–±–∏–≤–∞–µ—Ç –≤–∏–¥–µ–æ –Ω–∞ –∫–∞–¥—Ä—ã –∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤ WebDAV —Å –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö."""
    local_client = Client(WEBDAV_OPTIONS)
    cap = cv2.VideoCapture(video_path)
    existing_frames = count_remote_frames(webdav_client=local_client)
    logger.info(f"–ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã –∏–∑ {video_path}. FPS - {frames_per_second}")
    if existing_frames >= 5000:
        logger.warning(
            f"–ü—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∫–∞–¥—Ä–æ–≤ –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ ({existing_frames} >= 5000). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∏–¥–µ–æ {video_path}.")
        cap.release()
        return video_path, False

    if not cap.isOpened():
        logger.error(f"–û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –≤–∏–¥–µ–æ {video_path}")
        return video_path, False  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–∏–¥–µ–æ —Å –æ—à–∏–±–∫–æ–π

    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps <= 0:
        logger.error(f"–û—à–∏–±–∫–∞: FPS –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω –¥–ª—è {video_path}")
        cap.release()
        return video_path, False

    frame_interval = max(int(fps / frames_per_second), 1)
    frame_count = 0
    saved_frame_count = 0
    max_retries = 3  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–µ

    logger.info(
        f"–ò–∑–≤–ª–µ–∫–∞–µ–º –∫–∞–¥—Ä—ã –∏–∑ {video_path} (FPS: {fps}, –ò–Ω—Ç–µ—Ä–≤–∞–ª: {frame_interval})")

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        if frame_count % frame_interval == 0:
            frame_filename = f"{Path(video_path).stem}_{saved_frame_count:06d}.jpg"
            local_frame_path = os.path.join(FRAME_DIR_TEMP, frame_filename)
            remote_frame_path = f"{REMOTE_FRAME_DIR}/{frame_filename}"

            cv2.imwrite(local_frame_path, frame)
            if os.path.exists(local_frame_path):
                success = False
                for attempt in range(1, max_retries + 1):
                    try:
                        local_client.upload_sync(remote_path=remote_frame_path,
                                                 local_path=local_frame_path)
                        os.remove(local_frame_path)
                        success = True
                        break  # –£—Å–ø–µ—à–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞, –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞
                    except Exception as e:
                        logger.error(
                            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–∞–¥—Ä–∞ {frame_filename} (–ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries}): {e}")
                        time.sleep(5)  # –ñ–¥–µ–º 5 —Å–µ–∫—É–Ω–¥ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –ø–æ–ø—ã—Ç–∫–æ–π

                if not success:
                    logger.error(
                        f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–∞–¥—Ä {frame_filename} –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫.")
                    cap.release()
                    return video_path, False
            else:
                logger.warning(
                    f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –ö–∞–¥—Ä {local_frame_path} –Ω–µ –±—ã–ª —Å–æ–∑–¥–∞–Ω.")
            saved_frame_count += 1
        frame_count += 1

    cap.release()
    logger.info(
        f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–æ {saved_frame_count} –∫–∞–¥—Ä–æ–≤ –∏–∑ {video_path}")
    return True, video_path, saved_frame_count


def cleanup_videos():
    """–£–¥–∞–ª—è–µ—Ç –ª–æ–∫–∞–ª—å–Ω—ã–µ –≤–∏–¥–µ–æ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    logger.info("–£–¥–∞–ª–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –≤–∏–¥–µ–æ")
    videos = [os.path.join(LOCAL_VIDEO_DIR, f) for f in
              os.listdir(LOCAL_VIDEO_DIR) if
              f.endswith(".mp4")]
    for video in videos:
        os.remove(video)
        logger.debug(f"Deleted {video}")


def sync_label_studio_storage():
    """
    –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞ –≤ Label Studio —á–µ—Ä–µ–∑ API.

    :return: –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ (True - —É—Å–ø–µ—Ö, False - –æ—à–∏–±–∫–∞)
    """
    remount_webdav()
    sync_url = f"{LABELSTUDIO_HOST}:{LABELSTUDIO_PORT}/api/storages/localfiles/{LABELSTUDIO_STORAGE_ID}/sync"

    response = requests.post(sync_url, headers=HEADERS)

    if response.status_code == 200:
        logger.info("–•—Ä–∞–Ω–∏–ª–∏—â–µ —É—Å–ø–µ—à–Ω–æ —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–æ–≤–∞–Ω–æ")
        return True
    else:
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏: {response.text}")
        return False


'''
def delete_blacklisted_files():
    """–£–¥–∞–ª—è–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—á–∏–Ω–∞—é—Ç—Å—è —Å '018270348452'."""
    PREFIX_TO_DELETE = "018270348452"  # –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è

    def traverse_and_delete(path):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –æ–±—Ö–æ–¥–∏—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –∏ —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª—ã —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –ø—Ä–µ—Ñ–∏–∫—Å–æ–º."""
        items = client.list(path)
        for item in items:
            item_path = sanitize_path(f"{path}/{item}")

            if client.is_dir(item_path):
                traverse_and_delete(item_path)  # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –∏–¥—ë–º –≤–Ω—É—Ç—Ä—å
            elif item.startswith(PREFIX_TO_DELETE):
                print(f"üóë –£–¥–∞–ª—è—é —Ñ–∞–π–ª: {item_path}")
                client.clean(item_path)  # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª

    traverse_and_delete(REMOTE_FRAME_DIR)
'''


def main_process_new_frames(max_frames=3000, only_cargo_type: str = None, fps: float = None, video_name: str = None):
    logger.info("\n\U0001f504 –ó–∞–ø—É—â–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Å–æ–∑–¥–∞–Ω–∏—è —Ñ—Ä–µ–π–º–æ–≤")
    result = process_video_loop(max_frames=max_frames, only_cargo_type=only_cargo_type, fps=fps, concrete_video_name=video_name)
    remount_webdav()
    time.sleep(3)
    sync_label_studio_storage()
    cleanup_videos()
    result["status"] = "frames processed"
    for item in client.list(REMOTE_FRAME_DIR):
        client.check(item)
    return result



def with_retries(func, max_attempts=3, delay=1.0, jitter=0.5, exceptions=(Exception,), log_prefix=""):
    for attempt in range(1, max_attempts + 1):
        try:
            return func()
        except exceptions as e:
            if attempt == max_attempts:
                raise
            logger.warning(f"{log_prefix}–û—à–∏–±–∫–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt}/{max_attempts}): {e}. –ü–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {delay} —Å–µ–∫.")
            time.sleep(delay + random.uniform(0, jitter))


def parse_video_name(video_name: str):
    """–ü–∞—Ä—Å–∏—Ç –∏–º—è —Ñ–∞–π–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (reg_id, day, base_name)."""
    pattern = re.compile(
        r"(?P<reg_id>[A-Z0-9]+)_(?P<year>\d{4})\.(?P<month>\d{1,2})\.(?P<day>\d{1,2}) "
        r"(?P<start_time>\d{1,2}\.\d{1,2}\.\d{1,2})-(?P<end_time>\d{1,2}\.\d{1,2}\.\d{1,2})"
        r"\.(?P<video_format>\w+)"
    )
    match = pattern.match(video_name)
    if not match:
        raise ValueError(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∏–º–µ–Ω–∏: {video_name}")

    reg_id = match.group("reg_id")
    day = f"{match.group('year')}.{match.group('month')}.{match.group('day')}"
    base_name = video_name.rsplit('.', 1)[0]
    return reg_id, day, base_name

def resolve_video_path(concrete_video_name: str, base_remote_dir: str, client) -> str:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ .mp4-—Ñ–∞–π–ª—É –ø–æ –∏–º–µ–Ω–∏ –≤–∏–¥–µ–æ.
    –ü—Ä–∏–º–µ—Ä: concrete_video_name = "K630AX702_2025.5.21 8.54.11-8.55.34.mp4"
    """
    reg_id, day, base_name = parse_video_name(concrete_video_name)
    remote_dir = f"{base_remote_dir}/{reg_id}/{day}/{base_name}"
    try:
        items = client.list(remote_dir)
    except Exception as e:
        raise FileNotFoundError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –ø–∞–ø–∫—É: {remote_dir}. –û—à–∏–±–∫–∞: {e}")

    mp4_files = [f for f in items if f.endswith(".mp4")]
    if not mp4_files:
        raise FileNotFoundError(f"–í –ø–∞–ø–∫–µ {remote_dir} –Ω–µ—Ç .mp4 —Ñ–∞–π–ª–æ–≤")

    return f"{remote_dir}/{mp4_files[0]}"

def process_video_loop(max_frames=3000, only_cargo_type: str = None, fps: float = None, concrete_video_name: str = None):
    remount_webdav()
    os.makedirs(LOCAL_VIDEO_DIR, exist_ok=True)
    downloaded_video_counter = 0

    # –£—Å–∫–æ—Ä—è–µ–º –ø–æ–∏—Å–∫ –≤–∏–¥–µ–æ, —Ä–∞—Å–ø–∞—Ä—Å–∏–≤ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –≤—ã–ø–æ–ª–Ω—è—è –ø–æ–∏—Å–∫ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞–ø–∫–µ
    if concrete_video_name:
        try:
            resolved_path = resolve_video_path(concrete_video_name, BASE_REMOTE_DIR, client)
            video_generator = iter([resolved_path])  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–µ –≤–∏–¥–µ–æ
        except Exception as e:
            return {"error": f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–∏ –ø—É—Ç–∏ –∫ –≤–∏–¥–µ–æ {concrete_video_name}: {e}"}
    else:
        remote_dir = BASE_REMOTE_DIR
        video_generator = iter_video_files(remote_dir)

    result_dict = {"total_frames_downloaded": 0, "vid_process_results": [], "total_frames_in_storage": 0}
    while True:

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ
        try:
            items = with_retries(lambda: client.list(REMOTE_FRAME_DIR), log_prefix="[WebDAV:list REMOTE_FRAME_DIR] ")
            frame_count = sum(1 for item in items if item.endswith(".jpg"))
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ –ª–∏–º–∏—Ç–∞ –∫–∞–¥—Ä–æ–≤: {e}")
            break

        if frame_count >= max_frames:
            logger.info(f"\n–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∫–∞–¥—Ä–æ–≤ ({frame_count}/{max_frames}). –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏.")
            if not downloaded_video_counter:
                return {"error": f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç –∫–∞–¥—Ä–æ–≤ ({frame_count}/{max_frames})"}
            else:
                return result_dict
        #else:
        #   logger.info(f"\n–í –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –≤ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ ({frame_count}/{max_frames}). –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É.")

        try:
            video = next(video_generator)
        except StopIteration:
            logger.info("–í—Å–µ –≤–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã")
            return {"error": "–í—Å–µ –≤–∏–¥–µ–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã"}

        current_video_name = os.path.basename(video)
        if concrete_video_name and concrete_video_name != current_video_name:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª: {current_video_name} (–∏—â–µ–º –≤–∏–¥–µ–æ {concrete_video_name})")
            continue

        if video in downloaded_videos and not concrete_video_name:
            logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω–æ {video}, —É–∂–µ —Å–∫–∞—á–∞–Ω–æ.")
            continue

        # ‚ûï –ü–æ–ª—É—á–∞–µ–º —Ç–∏–ø –≥—Ä—É–∑–∞ –∏–∑ report.json
        report_path = os.path.join(os.path.dirname(video), "report.json")
        try:
            with tempfile.NamedTemporaryFile(mode="w+b", delete=False) as tmpf:
                client.download_sync(remote_path=report_path, local_path=tmpf.name)
                tmpf.seek(0)
                report_data = json.load(tmpf)
                switch_events = report_data.get("switch_events", [])
                if switch_events and isinstance(switch_events, list):
                    switch_code = switch_events[0].get("switch")
                    if switch_code == 22:
                        cargo_type = "bunker"
                    elif switch_code == 23:
                        cargo_type = "euro"
                    else:
                        cargo_type = "unknown"
                    logger.info(f"[TYPE] {video} ‚Üí —Ç–∏–ø –≥—Ä—É–∑–∞: {cargo_type} (switch={switch_code})")
                else:
                    logger.warning(f"[WARN] –ù–µ—Ç switch_events –≤ {report_path}")
        except Exception as e:
            logger.warning(f"[WARN] –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–ª–∏ —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å report.json –¥–ª—è {video}: {e}")

        if only_cargo_type and cargo_type != only_cargo_type:
            logger.debug(f"–¢–∏–ø –≥—Ä—É–∑–∞ - {cargo_type}. –ù–æ –∫–∞—á–∞–µ–º —Ç–æ–ª—å–∫–æ - {only_cargo_type}, –ø—Ä–æ–ø—É—Å–∫...")
            continue

        local_path = os.path.join(LOCAL_VIDEO_DIR, current_video_name)
        logger.info(f"–°–∫–∞—á–∏–≤–∞–Ω–∏–µ {video}")
        try:
            temp_path = local_path + ".part"
            with_retries(lambda: client.download_sync(remote_path=video, local_path=temp_path),
                         log_prefix=f"[WebDAV:download {video}] ")
            os.rename(temp_path, local_path)
            downloaded_videos.add(video)
            logger.info(f"–°–∫–∞—á–∞–Ω–æ {video} –≤ {local_path}")
            downloaded_video_counter += 1
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–∏ {video}: {e}")
            continue

        # –ù–∞—Ä–µ–∑–∞–µ–º –∫–∞–¥—Ä—ã —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
        logger.info(f"–ù–∞—Ä–µ–∑–∫–∞ –∫–∞–¥—Ä–æ–≤ –∏–∑ {local_path}")
        if not fps:
            fps = 1 if cargo_type == "euro" else 0.25
        success, video_path, frames = (extract_frames(local_path, frames_per_second=fps))
        if not success:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –≤–∏–¥–µ–æ: {video_path}")
        result_dict["vid_process_results"].append({"video_path": video_path, "frames": frames, "success": success})
        result_dict["total_frames_downloaded"] += int(frames)
        result_dict["total_frames_in_storage"] = frame_count + int(frames)
        save_download_history()
        if concrete_video_name:
            break
    return result_dict


